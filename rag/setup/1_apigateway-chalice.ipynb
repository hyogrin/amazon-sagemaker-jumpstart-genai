{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7622786b-8e91-4039-aecb-ea168663ce81",
   "metadata": {},
   "source": [
    "# Create Serverless endpoint using AWS Chalice\n",
    "---\n",
    "\n",
    "**[주의] 이 핸즈온 코드는 워크샵 참석자가 아닌 워크샵 진행자(호스트)가 실행하는 코드입니다!**\n",
    "\n",
    "### AWS Chalice란?\n",
    "\n",
    "\n",
    "AWS Chalice는 AWS의 오픈 소스 서버리스 프레임워크로 빠르고 쉽게 서버리스 어플리케이션을 구축할 수 있습니다. Flask 스타일의 마이크로 웹 프레임워크를 기반으로 하고 있으며, 자동으로 AWS Lambda 함수를 생성하고 API Gateway 엔드포인트를 구성해 줍니다. 또한 Amazon DynamoDB, Amazon S3, SQS, SNS 등과 같은 서비스의 통합도 지원합니다.\n",
    "\n",
    "Chalice는 간단한 웹 애플리케이션 및 마이크로 서비스와 같은 작은 규모의 빠른 프로토타이핑 및 서버리스 애플리케이션 개발에 유용하며, 데이터 과학자가 Lambda 및 API Gateway와 같은 AWS 서비스에 대한 지식이 없더라도 쉽게 사용할 수 있습니다. 또한 Chalice는 일부 내장된 보안 기능, 로깅 및 오류 처리 기능을 제공하므로 개발자는 이러한 작업을 직접 처리할 필요가 없습니다.\n",
    "\n",
    "참조\n",
    "- https://aws.github.io/chalice/\n",
    "- https://github.com/daekeun-ml/aws-chalice-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a423d90-e8f1-424d-9e04-b71e506eade0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chalice\n",
      "  Obtaining dependency information for chalice from https://files.pythonhosted.org/packages/54/d9/fc8d0744740dd1db2490049ac3035002ec52cde7385d8d14416e829a3bc2/chalice-1.29.0-py3-none-any.whl.metadata\n",
      "  Using cached chalice-1.29.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: click<9.0,>=7 in /opt/conda/lib/python3.10/site-packages (from chalice) (8.1.3)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from chalice) (1.29.132)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from chalice) (4.5.0)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from chalice) (1.16.0)\n",
      "Collecting pip<23.2,>=9 (from chalice)\n",
      "  Using cached pip-23.1.2-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.9.3 in /opt/conda/lib/python3.10/site-packages (from chalice) (1.0.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from chalice) (5.4.1)\n",
      "Collecting inquirer<3.0.0,>=2.7.0 (from chalice)\n",
      "  Using cached inquirer-2.10.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from chalice) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from chalice) (65.6.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<2.0.0,>=1.14.0->chalice) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<2.0.0,>=1.14.0->chalice) (1.26.14)\n",
      "Collecting blessed>=1.19.0 (from inquirer<3.0.0,>=2.7.0->chalice)\n",
      "  Using cached blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting python-editor>=1.0.4 (from inquirer<3.0.0,>=2.7.0->chalice)\n",
      "  Using cached python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting readchar>=3.0.6 (from inquirer<3.0.0,>=2.7.0->chalice)\n",
      "  Using cached readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.19.0->inquirer<3.0.0,>=2.7.0->chalice) (0.2.6)\n",
      "Using cached chalice-1.29.0-py3-none-any.whl (264 kB)\n",
      "Installing collected packages: python-editor, readchar, pip, blessed, inquirer, chalice\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "Successfully installed blessed-1.20.0 chalice-1.29.0 inquirer-2.10.1 pip-23.1.2 python-editor-1.0.4 readchar-4.0.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install chalice\n",
    "# #!sudo yum -y install tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3130d816-6726-4ded-bb32-0394efe11fb7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Create a project\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27bf8b4d-5c1c-49fa-8a12-2456c0ed935c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your project has been generated in ./genai-rag-workshop\n"
     ]
    }
   ],
   "source": [
    "PROJECT = \"genai-rag-workshop\"\n",
    "!rm -rf $PROJECT\n",
    "!chalice new-project $PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7a49f1d-faeb-4176-bfa7-ab0a10cb3281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"version\": \"2.0\",\n",
      "  \"app_name\": \"genai-rag-workshop\",\n",
      "  \"stages\": {\n",
      "    \"dev\": {\n",
      "      \"api_gateway_stage\": \"api\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat $PROJECT/.chalice/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d663116-3c53-4fa6-8a03-35eaf12044d3",
   "metadata": {},
   "source": [
    "### SageMaker Endpoint name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0467d784-82c0-49da-9993-3cf5c7b963bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# us-east-1\n",
    "#endpoint_emb_kosimcse = 'KoSimCSE-roberta-2023-08-03-22-52-21'\n",
    "#endpoint_emb_gptj_6b = 'jumpstart-dft-hf-textembedding-gpt-j-6b-fp16'\n",
    "\n",
    "# us-west-2\n",
    "#endpoint_emb_kosimcse = 'KoSimCSE-roberta-2023-08-11-07-45-03' ##\n",
    "#endpoint_emb_gptj_6b = 'jumpstart-dft-hf-textembedding-gpt-j-6b-fp16-1' ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbc06b87-ad2c-4d8b-bcbc-536c6fcf8648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# us-east-1\n",
    "# endpoint_llm_llama2_7b = 'jumpstart-dft-meta-textgeneration-llama-2-7b-1'\n",
    "# endpoint_llm_llama2_13b = 'jumpstart-dft-meta-textgeneration-llama-2-13b'\n",
    "endpoint_llm_kkulm_12_8b = 'kullm-polyglot-12-8b-v2-1694183328'\n",
    "# endpoint_llm_falcon_40b = 'jumpstart-dft-hf-llm-falcon-40b-instruct-bf16'\n",
    "\n",
    "# us-west-2\n",
    "#endpoint_llm_llama2_7b = 'jumpstart-dft-meta-textgeneration-llama-2-7b-1-1' ##\n",
    "#endpoint_llm_llama2_13b = 'jumpstart-dft-meta-textgeneration-llama-2-13b-1' ##\n",
    "#endpoint_llm_kkulm_12_8b = 'kullm-polyglot-12-8b-v2-1694183328' ##\n",
    "#endpoint_llm_falcon_40b = 'jumpstart-dft-hf-llm-falcon-40b-instruct-bf16-1' ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe2b117f-203e-4796-a933-cfa6630dfbe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "    \"Version\": \"2.0\",\n",
      "    \"app_name\": \"{{app_name}}\",\n",
      "    \"autogen_policy\": false,\n",
      "    \"automatic_layer\": true,\n",
      "    \"environment_variables\": {\n",
      "        \"ENDPOINT_EMB_KOSIMCSE\": \"{{endpoint_emb_kosimcse}}\",        \n",
      "        \"ENDPOINT_EMB_GPTJ_6B\": \"{{endpoint_emb_gptj_6b}}\",        \n",
      "        \"ENDPOINT_LLM_LLAMA2_7B\": \"{{endpoint_llm_llama2_7b}}\",\n",
      "        \"ENDPOINT_LLM_LLAMA2_13B\": \"{{endpoint_llm_llama2_13b}}\",     \n",
      "        \"ENDPOINT_LLM_KKULM_12_8B\": \"{{endpoint_llm_kkulm_12_8b}}\",\n",
      "        \"ENDPOINT_LLM_FALCON_40B\": \"{{endpoint_llm_falcon_40b}}\"  \n",
      "    },\n",
      "    \"stages\": {\n",
      "        \"dev\": {\n",
      "            \"api_gateway_stage\": \"api\"\n",
      "        }    \n",
      "    }\n",
      "\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat $PROJECT/.chalice/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d680c68f-b01e-4297-941e-df07a3be3ca0",
   "metadata": {},
   "source": [
    "### Setup config.json\n",
    "Chalice는 IAM 정책 자동 생성 기능이 있지만, 필요한 정책을 가진 IAM 정책을 생성할수 있습니다. 기본적으로는 직접 IAM 정책을 생성하는 것이 안전합니다. <br>\n",
    "자세한 내용은 https://chalice-fei.readthedocs.io/en/latest/topics/configfile.html 를 참조하기 바랍니다.\n",
    "\n",
    "`autogen_policy`: \n",
    "- 애플리케이션 소스 코드 분석을 기반으로 chalice가 IAM 정책을 자동으로 생성할지 여부를 설정 (디폴트 = True)\n",
    "- False인 경우, `.chalice/policy-<단계 이름>.json`에서 IAM 정책을 로드\n",
    "- `iam_policy_file` 지정으로 불러올 policy 파일명을 변경할 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dcf5fed-f12e-4849-91bf-383ea0d1e879",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting genai-rag-workshop/.chalice/config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $PROJECT/.chalice/config.json\n",
    "\n",
    "{\n",
    "    \"Version\": \"2.0\",\n",
    "    \"app_name\": \"{{app_name}}\",\n",
    "    \"autogen_policy\": false,\n",
    "    \"automatic_layer\": true,\n",
    "    \"environment_variables\": {\n",
    "        \"ENDPOINT_EMB_KOSIMCSE\": \"{{endpoint_emb_kosimcse}}\",        \n",
    "        \"ENDPOINT_EMB_GPTJ_6B\": \"{{endpoint_emb_gptj_6b}}\",        \n",
    "        \"ENDPOINT_LLM_LLAMA2_7B\": \"{{endpoint_llm_llama2_7b}}\",\n",
    "        \"ENDPOINT_LLM_LLAMA2_13B\": \"{{endpoint_llm_llama2_13b}}\",     \n",
    "        \"ENDPOINT_LLM_KKULM_12_8B\": \"{{endpoint_llm_kkulm_12_8b}}\",\n",
    "        \"ENDPOINT_LLM_FALCON_40B\": \"{{endpoint_llm_falcon_40b}}\"  \n",
    "    },\n",
    "    \"stages\": {\n",
    "        \"dev\": {\n",
    "            \"api_gateway_stage\": \"api\"\n",
    "        }    \n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f16006e-a60c-4e0c-b1bf-33f500789099",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t{\u001b[37m\u001b[39;49;00m\n",
      "     2\t\u001b[37m    \u001b[39;49;00m\u001b[94m\"Version\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"2.0\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "     3\t\u001b[37m    \u001b[39;49;00m\u001b[94m\"app_name\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"genai-rag-workshop\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "     4\t\u001b[37m    \u001b[39;49;00m\u001b[94m\"autogen_policy\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34mfalse\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "     5\t\u001b[37m    \u001b[39;49;00m\u001b[94m\"automatic_layer\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34mtrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "     6\t\u001b[37m    \u001b[39;49;00m\u001b[94m\"environment_variables\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "     7\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"ENDPOINT_EMB_KOSIMCSE\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"KoSimCSE-roberta-2023-08-11-07-45-03\"\u001b[39;49;00m,\u001b[37m        \u001b[39;49;00m\n",
      "     8\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"ENDPOINT_EMB_GPTJ_6B\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"jumpstart-dft-hf-textembedding-gpt-j-6b-fp16-1\"\u001b[39;49;00m,\u001b[37m        \u001b[39;49;00m\n",
      "     9\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"ENDPOINT_LLM_LLAMA2_7B\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"jumpstart-dft-meta-textgeneration-llama-2-7b-1-1\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    10\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"ENDPOINT_LLM_LLAMA2_13B\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\"\u001b[39;49;00m,\u001b[37m     \u001b[39;49;00m\n",
      "    11\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"ENDPOINT_LLM_KKULM_12_8B\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"kullm-polyglot-12-8b-v2-1694183328\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    12\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"ENDPOINT_LLM_FALCON_40B\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"jumpstart-dft-hf-llm-falcon-40b-instruct-bf16-1\"\u001b[39;49;00m\u001b[37m  \u001b[39;49;00m\n",
      "    13\t\u001b[37m    \u001b[39;49;00m},\u001b[37m\u001b[39;49;00m\n",
      "    14\t\u001b[37m    \u001b[39;49;00m\u001b[94m\"stages\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "    15\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"dev\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "    16\t\u001b[37m            \u001b[39;49;00m\u001b[94m\"api_gateway_stage\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"api\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    17\t\u001b[37m        \u001b[39;49;00m}\u001b[37m    \u001b[39;49;00m\n",
      "    18\t\u001b[37m    \u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
      "    19\t\u001b[37m\u001b[39;49;00m\n",
      "    20\t}\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "import jinja2\n",
    "from pathlib import Path\n",
    "jinja_env = jinja2.Environment()  # jinja environment to generate model configuration templates\n",
    "# we plug in the appropriate model location into our `serving.properties` file based on the region in which this notebook is running\n",
    "template = jinja_env.from_string(Path(f\"{PROJECT}/.chalice/config.json\").open().read())\n",
    "Path(f\"{PROJECT}/.chalice/config.json\").open(\"w\").write(\n",
    "    template.render(\n",
    "        endpoint_emb_kosimcse=endpoint_emb_kosimcse,\n",
    "        endpoint_emb_gptj_6b=endpoint_emb_gptj_6b,\n",
    "        endpoint_llm_llama2_7b=endpoint_llm_llama2_7b,\n",
    "#        endpoint_llm_llama2_13b=endpoint_llm_llama2_13b,\n",
    "        endpoint_llm_kkulm_12_8b=endpoint_llm_kkulm_12_8b,\n",
    "        endpoint_llm_falcon_40b=endpoint_llm_falcon_40b,        \n",
    "        app_name=PROJECT\n",
    "    )\n",
    ")\n",
    "!pygmentize {PROJECT}/.chalice/config.json | cat -n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b8632-7a93-41b9-a45d-250fc46c19c5",
   "metadata": {},
   "source": [
    "#### Setup IAM policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72fcc9a6-ebcd-4be5-9566-b6326d859ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing genai-rag-workshop/.chalice/policy-dev.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $PROJECT/.chalice/policy-dev.json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"VisualEditor0\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"logs:CreateLogStream\",\n",
    "                \"logs:PutLogEvents\",\n",
    "                \"logs:CreateLogGroup\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:logs:*:*:*\"\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"VisualEditor1\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"sagemaker:InvokeEndpoint\",\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a77a0f7-1dc1-496c-b2be-e3dbbdc33db7",
   "metadata": {},
   "source": [
    "### Develop `app.py`\n",
    "\n",
    "app.py는 서버리스 마이크로프레임워크를 구성하는 핵심 스크립트입니다. 파이썬 데코레이터로(decorator)만으로 AWS의 핵심 서비스들을 쉽고 빠르게 설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db7da33c-f44b-4d12-a7ba-950afc9d79b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting genai-rag-workshop/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $PROJECT/app.py \n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from chalice import Chalice\n",
    "from chalice import BadRequestError\n",
    "\n",
    "app = Chalice(app_name=\"{{app_name}}\")\n",
    "app.debug = True\n",
    "\n",
    "smr_client = boto3.client(\"runtime.sagemaker\")\n",
    "logger = logging.getLogger(\"{{app_name}}\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return {'hello': 'world'}\n",
    "\n",
    "\n",
    "@app.route(\"/emb/{variant_name}\", methods=[\"POST\"], content_types=[\"application/json\"])\n",
    "def invoke_emb(variant_name):\n",
    "\n",
    "    models = ['gptj_6b', 'kosimcse']\n",
    "    if variant_name not in models:\n",
    "        raise BadRequestError(\"[ERROR] Invalid model!\")\n",
    "    \n",
    "    logger.info(f\"embedding model: {variant_name}\")\n",
    "\n",
    "    if variant_name == \"gptj_6b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_EMB_GPTJ_6B\"]\n",
    "    elif variant_name == \"kosimcse\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_EMB_KOSIMCSE\"]        \n",
    "\n",
    "    payload = app.current_request.json_body\n",
    "\n",
    "    try:\n",
    "        response = smr_client.invoke_endpoint(\n",
    "            EndpointName=endpoint_name, \n",
    "            ContentType='application/json',                        \n",
    "            Body=json.dumps(payload).encode(\"utf-8\")\n",
    "        ) \n",
    "        res = response['Body'].read()\n",
    "        return json.loads(res.decode(\"utf-8\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(payload)\n",
    "        \n",
    "        \n",
    "@app.route(\"/llm/{variant_name}\", methods=[\"POST\"], content_types=[\"application/json\"])\n",
    "def invoke_llm(variant_name):\n",
    "    \n",
    "    models = ['llama2_7b', 'llama2_13b', 'kkulm_12_8b', 'falcon_40b']\n",
    "    if variant_name not in models:\n",
    "        raise BadRequestError(\"[ERROR] Invalid model!\")\n",
    "        \n",
    "    logger.info(f\"txt2txt model: {variant_name}\")\n",
    "\n",
    "    if variant_name == \"llama2_7b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_LLAMA2_7B\"]\n",
    "    elif variant_name == \"llama2_13b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_LLAMA2_13B\"]\n",
    "    elif variant_name == \"kkulm_12_8b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_KKULM_12_8B\"]\n",
    "    elif variant_name == \"kkulm_12_8b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_KKULM_12_8B\"]\n",
    "    elif variant_name == \"falcon_40b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_FALCON_40B\"]        \n",
    "\n",
    "    payload = app.current_request.json_body\n",
    "\n",
    "    try:\n",
    "        if \"llama2\" in variant_name:\n",
    "            response = smr_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name, \n",
    "                ContentType='application/json',                        \n",
    "                Body=json.dumps(payload).encode(\"utf-8\"),\n",
    "                CustomAttributes=\"accept_eula=true\",\n",
    "            )\n",
    "        else:\n",
    "             response = smr_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name, \n",
    "                ContentType='application/json',                        \n",
    "                Body=json.dumps(payload).encode(\"utf-8\")\n",
    "            )           \n",
    "        res = response['Body'].read()\n",
    "        return json.loads(res.decode(\"utf-8\"))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "379535eb-69e7-4300-afda-697d165ce2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     2\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     3\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     4\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     5\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mbase64\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     6\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     7\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     8\t\u001b[37m\u001b[39;49;00m\n",
      "     9\t\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mchalice\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Chalice\u001b[37m\u001b[39;49;00m\n",
      "    10\t\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mchalice\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m BadRequestError\u001b[37m\u001b[39;49;00m\n",
      "    11\t\u001b[37m\u001b[39;49;00m\n",
      "    12\tapp = Chalice(app_name=\u001b[33m\"\u001b[39;49;00m\u001b[33mgenai-rag-workshop\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    13\tapp.debug = \u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    14\t\u001b[37m\u001b[39;49;00m\n",
      "    15\tsmr_client = boto3.client(\u001b[33m\"\u001b[39;49;00m\u001b[33mruntime.sagemaker\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    16\tlogger = logging.getLogger(\u001b[33m\"\u001b[39;49;00m\u001b[33mgenai-rag-workshop\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    17\tlogger.setLevel(logging.DEBUG)\u001b[37m\u001b[39;49;00m\n",
      "    18\t\u001b[37m\u001b[39;49;00m\n",
      "    19\t\u001b[90m@app\u001b[39;49;00m.route(\u001b[33m\"\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    20\t\u001b[34mdef\u001b[39;49;00m \u001b[32mindex\u001b[39;49;00m():\u001b[37m\u001b[39;49;00m\n",
      "    21\t    \u001b[34mreturn\u001b[39;49;00m {\u001b[33m'\u001b[39;49;00m\u001b[33mhello\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mworld\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
      "    22\t\u001b[37m\u001b[39;49;00m\n",
      "    23\t\u001b[37m\u001b[39;49;00m\n",
      "    24\t\u001b[90m@app\u001b[39;49;00m.route(\u001b[33m\"\u001b[39;49;00m\u001b[33m/emb/\u001b[39;49;00m\u001b[33m{variant_name}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, methods=[\u001b[33m\"\u001b[39;49;00m\u001b[33mPOST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], content_types=[\u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    25\t\u001b[34mdef\u001b[39;49;00m \u001b[32minvoke_emb\u001b[39;49;00m(variant_name):\u001b[37m\u001b[39;49;00m\n",
      "    26\t\u001b[37m\u001b[39;49;00m\n",
      "    27\t    models = [\u001b[33m'\u001b[39;49;00m\u001b[33mgptj_6b\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mkosimcse\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    28\t    \u001b[34mif\u001b[39;49;00m variant_name \u001b[35mnot\u001b[39;49;00m \u001b[35min\u001b[39;49;00m models:\u001b[37m\u001b[39;49;00m\n",
      "    29\t        \u001b[34mraise\u001b[39;49;00m BadRequestError(\u001b[33m\"\u001b[39;49;00m\u001b[33m[ERROR] Invalid model!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    30\t    \u001b[37m\u001b[39;49;00m\n",
      "    31\t    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33membedding model: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvariant_name\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    32\t\u001b[37m\u001b[39;49;00m\n",
      "    33\t    \u001b[34mif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mgptj_6b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    34\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_EMB_GPTJ_6B\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    35\t    \u001b[34melif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mkosimcse\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    36\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_EMB_KOSIMCSE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]        \u001b[37m\u001b[39;49;00m\n",
      "    37\t\u001b[37m\u001b[39;49;00m\n",
      "    38\t    payload = app.current_request.json_body\u001b[37m\u001b[39;49;00m\n",
      "    39\t\u001b[37m\u001b[39;49;00m\n",
      "    40\t    \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    41\t        response = smr_client.invoke_endpoint(\u001b[37m\u001b[39;49;00m\n",
      "    42\t            EndpointName=endpoint_name, \u001b[37m\u001b[39;49;00m\n",
      "    43\t            ContentType=\u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,                        \u001b[37m\u001b[39;49;00m\n",
      "    44\t            Body=json.dumps(payload).encode(\u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    45\t        ) \u001b[37m\u001b[39;49;00m\n",
      "    46\t        res = response[\u001b[33m'\u001b[39;49;00m\u001b[33mBody\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].read()\u001b[37m\u001b[39;49;00m\n",
      "    47\t        \u001b[34mreturn\u001b[39;49;00m json.loads(res.decode(\u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    48\t\u001b[37m\u001b[39;49;00m\n",
      "    49\t    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\u001b[37m\u001b[39;49;00m\n",
      "    50\t        \u001b[36mprint\u001b[39;49;00m(e)\u001b[37m\u001b[39;49;00m\n",
      "    51\t        \u001b[36mprint\u001b[39;49;00m(payload)\u001b[37m\u001b[39;49;00m\n",
      "    52\t        \u001b[37m\u001b[39;49;00m\n",
      "    53\t        \u001b[37m\u001b[39;49;00m\n",
      "    54\t\u001b[90m@app\u001b[39;49;00m.route(\u001b[33m\"\u001b[39;49;00m\u001b[33m/llm/\u001b[39;49;00m\u001b[33m{variant_name}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, methods=[\u001b[33m\"\u001b[39;49;00m\u001b[33mPOST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], content_types=[\u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    55\t\u001b[34mdef\u001b[39;49;00m \u001b[32minvoke_llm\u001b[39;49;00m(variant_name):\u001b[37m\u001b[39;49;00m\n",
      "    56\t    \u001b[37m\u001b[39;49;00m\n",
      "    57\t    models = [\u001b[33m'\u001b[39;49;00m\u001b[33mllama2_7b\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mllama2_13b\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mkkulm_12_8b\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfalcon_40b\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    58\t    \u001b[34mif\u001b[39;49;00m variant_name \u001b[35mnot\u001b[39;49;00m \u001b[35min\u001b[39;49;00m models:\u001b[37m\u001b[39;49;00m\n",
      "    59\t        \u001b[34mraise\u001b[39;49;00m BadRequestError(\u001b[33m\"\u001b[39;49;00m\u001b[33m[ERROR] Invalid model!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    60\t        \u001b[37m\u001b[39;49;00m\n",
      "    61\t    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mtxt2txt model: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvariant_name\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    62\t\u001b[37m\u001b[39;49;00m\n",
      "    63\t    \u001b[34mif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mllama2_7b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    64\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_LLM_LLAMA2_7B\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    65\t    \u001b[34melif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mllama2_13b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    66\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_LLM_LLAMA2_13B\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    67\t    \u001b[34melif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mkkulm_12_8b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    68\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_LLM_KKULM_12_8B\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    69\t    \u001b[34melif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mkkulm_12_8b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    70\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_LLM_KKULM_12_8B\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    71\t    \u001b[34melif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mfalcon_40b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    72\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_LLM_FALCON_40B\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]        \u001b[37m\u001b[39;49;00m\n",
      "    73\t\u001b[37m\u001b[39;49;00m\n",
      "    74\t    payload = app.current_request.json_body\u001b[37m\u001b[39;49;00m\n",
      "    75\t\u001b[37m\u001b[39;49;00m\n",
      "    76\t    \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    77\t        \u001b[34mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mllama2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[35min\u001b[39;49;00m variant_name:\u001b[37m\u001b[39;49;00m\n",
      "    78\t            response = smr_client.invoke_endpoint(\u001b[37m\u001b[39;49;00m\n",
      "    79\t                EndpointName=endpoint_name, \u001b[37m\u001b[39;49;00m\n",
      "    80\t                ContentType=\u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,                        \u001b[37m\u001b[39;49;00m\n",
      "    81\t                Body=json.dumps(payload).encode(\u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "    82\t                CustomAttributes=\u001b[33m\"\u001b[39;49;00m\u001b[33maccept_eula=true\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    83\t            )\u001b[37m\u001b[39;49;00m\n",
      "    84\t        \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    85\t             response = smr_client.invoke_endpoint(\u001b[37m\u001b[39;49;00m\n",
      "    86\t                EndpointName=endpoint_name, \u001b[37m\u001b[39;49;00m\n",
      "    87\t                ContentType=\u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,                        \u001b[37m\u001b[39;49;00m\n",
      "    88\t                Body=json.dumps(payload).encode(\u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    89\t            )           \u001b[37m\u001b[39;49;00m\n",
      "    90\t        res = response[\u001b[33m'\u001b[39;49;00m\u001b[33mBody\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].read()\u001b[37m\u001b[39;49;00m\n",
      "    91\t        \u001b[34mreturn\u001b[39;49;00m json.loads(res.decode(\u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    92\t        \u001b[37m\u001b[39;49;00m\n",
      "    93\t    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\u001b[37m\u001b[39;49;00m\n",
      "    94\t        \u001b[36mprint\u001b[39;49;00m(e)\u001b[37m\u001b[39;49;00m\n",
      "    95\t        \u001b[36mprint\u001b[39;49;00m(payload)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "jinja_env = jinja2.Environment()  # jinja environment to generate model configuration templates\n",
    "# we plug in the appropriate model location into our `serving.properties` file based on the region in which this notebook is running\n",
    "template = jinja_env.from_string(Path(f\"{PROJECT}/app.py\").open().read())\n",
    "Path(f\"{PROJECT}/app.py\").open(\"w\").write(\n",
    "    template.render(\n",
    "        app_name=PROJECT,\n",
    "    )\n",
    ")\n",
    "!pygmentize {PROJECT}/app.py | cat -n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469f3ca-f296-4856-ba20-d8b1da70926e",
   "metadata": {},
   "source": [
    "### requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13429635-2a26-49a6-9895-16264f3f68a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting genai-rag-workshop/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $PROJECT/requirements.txt\n",
    "numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711fc89-bc58-44b3-840a-ff12f565a664",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Deploying\n",
    "---\n",
    "### Local Test\n",
    "로컬 환경에서 편리하게 테스트를 수행할 수 있습니다. 아래 코드는 SageMaker Studio에서는 동작하지 않습니다!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57a9a010-77e6-4801-9bfc-6b16464c53c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cd $PROJECT && chalice local --port=8200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cbd16-a374-428a-833b-cc1d4cedd818",
   "metadata": {},
   "source": [
    "```\n",
    "curl -X POST localhost:8200/llm/kkulm_12_8b -H \"Content-Type: application/json\" -d \"{ \\\"inputs\\\": \\\"피자 만드는 법을 알려줘\\\", \\\"max_length\\\":50, \\\"parameters\\\": {\\\"max_new_tokens\\\": 64, \\\"top_p\\\": 0.9} }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dccc535-b60e-48c3-9434-6f89703aece7",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "curl -X POST localhost:8200/llm/llama2_13b -H \"Content-Type: application/json\" -d \"{ \\\"inputs\\\": \\\"Tell me the steps to make a pizza\\\", \\\"max_length\\\":50, \\\"parameters\\\": {\\\"max_new_tokens\\\": 64, \\\"top_p\\\": 0.9} }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5153437d-4d9b-42ab-8e50-a6ac3d821279",
   "metadata": {},
   "source": [
    "```\n",
    "curl -X POST localhost:8200/emb/gptj_6b -H \"Content-Type: application/json\" -d \"{ \\\"text_inputs\\\": \\\"Tell me the steps to make a pizza\\\" }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48675b-d931-4e3f-89ce-d59be0cc7863",
   "metadata": {},
   "source": [
    "```\n",
    "curl -X POST localhost:8200/emb/kosimcse -H \"Content-Type: application/json\" -d \"{ \\\"inputs\\\": \\\"Tell me the steps to make a pizza\\\" }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0bfb08-38e6-4bed-97aa-154728b18318",
   "metadata": {},
   "source": [
    "### Deploy\n",
    "\n",
    "`chalice deploy`를 실행하면 자동으로 IAM Role, Lambda, API Gateway를 생성해 줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a86f880-339c-4dab-ac5b-5ff512c425d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Creating shared layer deployment package.\n",
      "Creating app deployment package.\n",
      "Creating lambda layer: genai-rag-workshop-dev-managed-layer\n",
      "Updating policy for IAM role: genai-rag-workshop-dev-api_handler\n",
      "Updating lambda function: genai-rag-workshop-dev\n",
      "Creating Rest API\n",
      "Resources deployed:\n",
      "  - Lambda Layer ARN: arn:aws:lambda:us-east-1:654405684375:layer:genai-rag-workshop-dev-managed-layer:2\n",
      "  - Lambda ARN: arn:aws:lambda:us-east-1:654405684375:function:genai-rag-workshop-dev\n",
      "  - Rest API URL: https://mfh8ekbt73.execute-api.us-east-1.amazonaws.com/api/\n"
     ]
    }
   ],
   "source": [
    "!cd $PROJECT && chalice deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6547005-a288-4f2c-b825-013c0ac564f8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. LLM Inference\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15405897-cebe-4933-b9e9-9fc390e00847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "\n",
    "client = boto3.client('apigateway')\n",
    "region = boto3.Session().region_name\n",
    "response = client.get_rest_apis(limit=1)\n",
    "\n",
    "RESTAPI_ID = response['items'][0]['id']\n",
    "\n",
    "URL = f'https://{RESTAPI_ID}.execute-api.{region}.amazonaws.com/api/'.replace('\"','')\n",
    "HEADERS = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23614952-edb7-4107-8f8d-b7d869bb8a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://mfh8ekbt73.execute-api.us-east-1.amazonaws.com/api/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df208e0b-34d9-4efd-8bf8-882989c7893f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mfh8ekbt73'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESTAPI_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556a633c-7a4c-4a01-a17e-31130507490e",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "curl -X POST https://6bk4r5mo4f.execute-api.us-east-1.amazonaws.com/api/llm/llama2_7b \\\n",
    "-H \"Content-Type: application/json\" -d \"{ \\\"inputs\\\": \\\"Tell me the steps to make a pizza\\\", \\\"max_length\\\":50, \\\"parameters\\\": {\\\"max_new_tokens\\\": 64, \\\"top_p\\\": 0.9} }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cbf7ba-88e7-4df9-93b3-919669f6df7a",
   "metadata": {},
   "source": [
    "### Llama 2-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0facbf56-d478-4949-abb9-31c2a79eed0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:14\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LLM_URL= f\"{URL}llm/llama2_7b\"\n",
    "\n",
    "payload = {\n",
    "    'inputs': \"Please let us know SageMaker's advantages in 100 words\",\n",
    "    'parameters': {\n",
    "        'max_new_tokens': 128,\n",
    "        'top_p': 0.9,\n",
    "        'temperature': 0.2,\n",
    "        'return_full_text': False\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "print(response.json()[0]['generation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55565775-0de6-4dce-b931-a054871460f3",
   "metadata": {},
   "source": [
    "### Llama 2-13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e1ad779-f399-474c-a307-44d4da4bd2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:14\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LLM_URL = f\"{URL}llm/llama2_13b\"\n",
    "\n",
    "payload = {\n",
    "    'inputs': \"Please let us know SageMaker's advantages in 100 words\",\n",
    "    'parameters': {\n",
    "        'max_new_tokens': 128,\n",
    "        'top_p': 0.9,\n",
    "        'temperature': 0.2,\n",
    "        'return_full_text': False\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "print(response.json()[0]['generation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27cf41c-28e2-4311-8805-2b90ff0c9a5f",
   "metadata": {},
   "source": [
    "### KKULM-polyglot-12.8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74fdd8c5-f4c5-4e5f-817b-815ac88964b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!​1. SageMaker는 데이터를 분석하고, 시각화하고, 인사이트를 도출하는 데 도움이 되는 다양한 도구와 기능을 제공합니다. 이러한 도구와 기능은 데이터 과학자, 데이터 분석가 및 데이터 과학자가 되고자 하는 사람들에게 필수적입니다.​2. SageMaker는 데이터 과학자, 데이터 분석가 및 데이터 과학자가 되고자 하는 사람들에게 필수적인 도구와 기능을 제공합니다. SageMaker는 데이터를 분석하고, 시각화하고, 인사이트를 도출하는 데 도움이\n",
      "CPU times: user 20.1 ms, sys: 0 ns, total: 20.1 ms\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = {\n",
    "    'inputs': \"SageMaker의 장점을 알려줘\",\n",
    "    'parameters': {\n",
    "        'max_new_tokens': 128,\n",
    "        'top_p': 0.9,\n",
    "        'temperature': 0.1,\n",
    "        'return_full_text': False\n",
    "    }\n",
    "}\n",
    "\n",
    "LLM_URL = f\"{URL}llm/kkulm_12_8b\"\n",
    "response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "print(response.json()[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6d84a-715e-4d14-9c0a-ba9169a57c77",
   "metadata": {},
   "source": [
    "### Falcon-40B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6183b-095c-421c-8caf-e7493bc2fb65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "LLM_URL = f\"{URL}llm/falcon_40b\"\n",
    "\n",
    "payload = {\n",
    "    'inputs': \"Please let us know SageMaker's advantages in 100 words\",\n",
    "    'parameters': {\n",
    "        'max_new_tokens': 128,\n",
    "        'top_p': 0.9,\n",
    "        'temperature': 0.2,\n",
    "        'return_full_text': False\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "print(response.json()[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0930a068-c903-4ab6-a166-a78ebd0b0bd8",
   "metadata": {},
   "source": [
    "### GPT-J-6B Embeddding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "749615ae-cdf9-44e6-9bac-3555c498c4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0005843630060553551, -0.0013202275149524212, 0.02084660902619362, 0.018653083592653275, 0.023699166253209114]\n",
      "CPU times: user 12.9 ms, sys: 2.64 ms, total: 15.5 ms\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = {\n",
    "    'text_inputs': \"embedding\",\n",
    "}\n",
    "\n",
    "EMB_URL = f\"{URL}emb/gptj_6b\"\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "}\n",
    "\n",
    "response = requests.post(url=EMB_URL, headers=headers, json=payload)\n",
    "print(response.json()['embedding'][0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c11100-8d0c-448d-bf96-a1bb43e9af6c",
   "metadata": {},
   "source": [
    "### KoSimCSE Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfd36b7-3faf-489d-8dc6-e8113222b3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "payload = {\n",
    "    'inputs': \"임베딩\",\n",
    "}\n",
    "\n",
    "EMB_URL = f\"{URL}emb/kosimcse\"\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "}\n",
    "\n",
    "response = requests.post(url=EMB_URL, headers=headers, json=payload)\n",
    "print(response.json()[0][0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca895d-060a-46ad-9851-831ef263c917",
   "metadata": {},
   "source": [
    "\n",
    "## Clean-up\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ba632-cfa9-4bcb-aff4-19fd2e55cec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store RESTAPI_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61206a6a-6019-47cc-91b2-7f9c093374e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd $PROJECT && chalice delete\n",
    "!rm -rf $PROJECT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272b177-8776-427a-92e2-dafa618161ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RESTAPI_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefdd456-576b-4a29-bfd4-5f1705156663",
   "metadata": {},
   "source": [
    "\n",
    "## Stress test (Ongoing)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142ff7c-cc87-4a7f-91c4-18616ea802f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55ab4b-8a39-4a4c-9f1c-68351bdf0799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def worker_llama2_7b(LLM_URL, words):\n",
    "    \n",
    "    print (LLM_URL, words)\n",
    "    \n",
    "    words = {\n",
    "        'inputs': f\"Please let us know SageMaker's advantages in 100 words\",\n",
    "        'parameters': {\n",
    "            'max_new_tokens': 128,\n",
    "            'top_p': 0.9,\n",
    "            'temperature': 0.2,\n",
    "            'return_full_text': False\n",
    "        }\n",
    "    }\n",
    "    print (words)\n",
    "\n",
    "    response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "    res = response.json()[0]['generation']\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d933d6f-3b1d-4d00-8d51-9c65f7b306e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def worker_falcon_40b(LLM_URL, words):\n",
    "    \n",
    "    print (LLM_URL, words)\n",
    "    \n",
    "    payload = {\n",
    "        'inputs': f\"Please let us know SageMaker's advantages in {100} words\",\n",
    "        #'inputs': inp,\n",
    "        \n",
    "        'parameters': {\n",
    "            'max_new_tokens': 128,\n",
    "            'top_p': 0.9,\n",
    "            'temperature': 0.2,\n",
    "            'return_full_text': False\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "    \n",
    "    if response.json() != None:\n",
    "        res = response.json()[0]['generated_text']\n",
    "    else:\n",
    "        res = \"None\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e295de6-63b8-42c2-b4af-f759404b680e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function = functools.partial(worker_falcon_40b, f\"{URL}llm/falcon_40b\") # 반복되는 것은 먼저 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a7a23e-1c4a-48c8-92eb-8a7d89496db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=60) as executor:\n",
    "    results = list(executor.map(function, [idx+1 for idx in range(60)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4fa51-4a6d-4e5a-8054-063dd81934b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(results), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2dbb1-4ea3-48a7-a603-f056dbb797ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
